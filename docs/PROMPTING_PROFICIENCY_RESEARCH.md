# Prompting Proficiency Assessment Research

## A Framework for Measuring User Prompting Ability from Commit History and Conversation Data

**Research Date**: December 2025
**Purpose**: Inform Claude Wrapped feature development for actionable user insights
**Scope**: Prompt Engineering, Context Engineering, Memory Engineering, Tool Use

---

## Executive Summary

This research synthesizes findings from 25+ academic papers, industry studies, and Anthropic documentation to answer a critical question: **How can we assess a user's prompting ability by analyzing their commit history and Claude conversation history?**

### Key Finding

No existing solution comprehensively assesses individual prompting ability from historical patterns. This represents a significant opportunity for Claude Wrapped to provide unique, actionable insights that improve users' future interactions across all AI models.

### Research Gap Identified

| Domain | Existing Solutions | Gap |
|--------|-------------------|-----|
| Prompt Quality | Metrics for individual prompts exist | No longitudinal skill assessment |
| Conversation Analysis | Multi-turn evaluation frameworks | No user proficiency scoring |
| Git Analysis | Developer behavior patterns | No AI-assisted coding correlation |
| Personalization | Instance-wise prompt optimization | No cross-session learning |

---

## Part 1: Research Foundations

### 1.1 Anthropic Research Findings

#### XML Formatting Impact
Anthropic specifically trained Claude to recognize XML structure, yielding **15-20% better performance** just from formatting changes. This is a measurable skill that can be detected in user prompts.

**Source**: [Anthropic Prompt Engineering Documentation](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)

#### Context Window Optimization
Anthropic's research on their 100K context window revealed two key techniques:
1. **Quote extraction before answering** improves recall
2. **Positioning instructions at END of prompts** optimizes retention

These techniques resulted in a **36% reduction in errors** for Claude 2.

**Source**: [Maginative - Anthropic Context Optimization](https://www.maginative.com/article/anthropic-shares-techniques-to-optimize-claudes-100k-context-window-for-better-recall/)

#### Memory Architecture
Claude's memory system distinguishes:
- **Project-level memory**: Isolated per workstream
- **Short-term memory**: Within-session context
- **Long-term memory**: Cross-session persistence via file-based storage

Users who effectively leverage these layers show measurably better outcomes.

**Source**: [Anthropic Memory Announcement](https://www.anthropic.com/news/memory)

### 1.2 Academic Paper Findings

#### Systematic Survey of Prompt Engineering (arXiv:2402.07927)

**Authors**: Pranab Sahoo et al. (February 2024, updated March 2025)

Key findings from analysis of 58+ prompting techniques:
- Complex prompting techniques **do not always outperform simple ones**
- Task-specific prompt selection is critical
- No universal "best" technique exists

**Implication for Proficiency Assessment**: Skilled users demonstrate technique selection ability, not just technique knowledge.

**Source**: [arXiv:2402.07927](https://arxiv.org/abs/2402.07927)

#### Enterprise Prompt Engineering Practices (arXiv:2403.08950)

**Key Discovery**: Analysis of enterprise prompt editing sessions revealed:
- Users iterate on **specific prompt components**
- Iteration patterns reveal **mental models** of how prompting works
- Effective prompting "is not trivial" and requires "skill and knowledge"

**Implication**: We can detect skill level by analyzing iteration patterns and component modifications.

**Source**: [arXiv:2403.08950](https://arxiv.org/abs/2403.08950)

#### Knowledge Gaps in Developer Prompts (arXiv:2501.11709)

**Critical Finding**:
- Ineffective conversations contain knowledge gaps in **54.7% of prompts**
- Effective conversations contain knowledge gaps in only **13.2% of prompts**

**Four Gap Types Identified**:
1. **Missing Context**: Insufficient background information
2. **Missing Specifications**: Unclear requirements
3. **Multiple Context**: Conflicting or redundant information
4. **Unclear Instructions**: Ambiguous requests

**Implication**: Gap detection is a high-signal indicator of prompting proficiency.

**Source**: [arXiv:2501.11709](https://arxiv.org/html/2501.11709v1)

#### From Prompting to Partnering (arXiv:2503.00681)

**Three Primary User Difficulties**:
1. Constructing effective prompts
2. Iteratively refining AI-generated responses
3. Assessing response reliability beyond personal expertise

**Proposed Solutions (validated in user testing)**:
- Reflective Prompting aids
- Section Regeneration for targeted refinement
- Input-Output Mapping for transparency
- Confidence Indicators
- Customization Panels

**Source**: [arXiv:2503.00681](https://arxiv.org/abs/2503.00681)

#### Context Engineering Survey (arXiv:2507.13334)

**Comprehensive Analysis**: Reviewed 1300+ research papers

**Key Insight**: Fundamental asymmetry existsâ€”models demonstrate remarkable proficiency in **understanding** complex contexts but exhibit pronounced limitations in **generating** equally sophisticated outputs.

**Three Pillars of Context Engineering**:
1. Context Retrieval and Generation
2. Context Processing (long sequences, self-refinement)
3. Context Management (memory hierarchies, compression)

**Source**: [arXiv:2507.13334](https://arxiv.org/html/2507.13334v1)

#### Multi-Turn Conversation Evaluation (arXiv:2503.22458)

**Five Evaluation Dimensions**:
1. Task Completion in Multi-Turn Conversations
2. Multitask Capabilities across domains
3. Interaction Patterns (recollection, follow-up, expansion, refinement)
4. Temporal Dimensions (context maintenance over time)
5. User Experience and Safety

**Four Interaction Pattern Types**:
- **Recollection**: Referencing earlier context
- **Expansion**: Building on previous responses
- **Refinement**: Narrowing or correcting outputs
- **Follow-up**: Logical continuation queries

**Source**: [arXiv:2503.22458](https://arxiv.org/html/2503.22458v1)

### 1.3 Industry Research Findings

#### Prompt Quality Metrics (CARE Framework)

**Components**:
- **C**omplete: All necessary information provided
- **A**ccurate: Correct requirements specified
- **R**elevant: Task-appropriate content
- **E**fficient: Minimal token waste

**Source**: [LinkedIn - CARE Framework](https://www.linkedin.com/pulse/introducing-care-new-way-measure-effectiveness-prompts-reuven-cohen-ls9bf)

#### Clarity Impact Study

Research found that prompts with **numbered steps lead to 87% better compliance** compared to vague instructions.

**Source**: [KDnuggets - Measuring Prompt Effectiveness](https://www.kdnuggets.com/measuring-prompt-effectiveness-metrics-and-methods)

#### Coherence Importance

Coherence influences **32% of user satisfaction** compared to 21% for clarity alone.

**Source**: [KDnuggets - Measuring Prompt Effectiveness](https://www.kdnuggets.com/measuring-prompt-effectiveness-metrics-and-methods)

#### AI-Assisted Coding Patterns (GitClear 2025)

**Concerning Findings**:
- **4x growth in code clones** when developers copy AI patterns without customization
- **19% increase in completion time** for experienced developers using AI
- **4x increase in defect rates** in AI-assisted code across 211M changed lines

**Positive Findings**:
- **55% productivity improvement** reported for GitHub Copilot
- **88% retention rate** for Copilot suggestions
- **26% average productivity gains** across enterprise deployments

**Implication**: There's significant variance in how effectively users leverage AI coding assistance.

**Source**: [GitClear Code Analysis](https://www.gitclear.com/code_analysis_beyond_lines_of_code)

#### JetBrains Context Management Research (NeurIPS 2025)

Identified significant gap in efficiency-based context management. Proposed hybrid approach achieving significant cost reduction through smart context selection.

**Source**: [JetBrains Research Blog](https://blog.jetbrains.com/research/2025/12/efficient-context-management/)

---

## Part 2: Proposed Proficiency Framework

### 2.1 Four Skill Dimensions

Based on research synthesis, we propose measuring prompting proficiency across four dimensions:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PROMPTING PROFICIENCY MODEL                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚    DIMENSION 1  â”‚  â”‚    DIMENSION 2  â”‚                   â”‚
â”‚  â”‚     PROMPT      â”‚  â”‚     CONTEXT     â”‚                   â”‚
â”‚  â”‚   ENGINEERING   â”‚  â”‚   ENGINEERING   â”‚                   â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚                   â”‚
â”‚  â”‚ â€¢ Clarity       â”‚  â”‚ â€¢ Selection     â”‚                   â”‚
â”‚  â”‚ â€¢ Specificity   â”‚  â”‚ â€¢ Compression   â”‚                   â”‚
â”‚  â”‚ â€¢ Technique     â”‚  â”‚ â€¢ Positioning   â”‚                   â”‚
â”‚  â”‚ â€¢ Iteration     â”‚  â”‚ â€¢ Management    â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚    DIMENSION 3  â”‚  â”‚    DIMENSION 4  â”‚                   â”‚
â”‚  â”‚     MEMORY      â”‚  â”‚    TOOL USE     â”‚                   â”‚
â”‚  â”‚   ENGINEERING   â”‚  â”‚   PROFICIENCY   â”‚                   â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚                   â”‚
â”‚  â”‚ â€¢ Short-term    â”‚  â”‚ â€¢ Discovery     â”‚                   â”‚
â”‚  â”‚ â€¢ Long-term     â”‚  â”‚ â€¢ Composition   â”‚                   â”‚
â”‚  â”‚ â€¢ Project       â”‚  â”‚ â€¢ Parallelism   â”‚                   â”‚
â”‚  â”‚ â€¢ Hygiene       â”‚  â”‚ â€¢ Recovery      â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Dimension 1: Prompt Engineering Proficiency

#### Measurable Signals from Conversation History

| Signal | Detection Method | Weight |
|--------|-----------------|--------|
| **Clarity Score** | NLP analysis for vagueness markers, imperative statements | 25% |
| **Specificity Score** | Presence of constraints, formats, examples | 25% |
| **Technique Usage** | Detection of CoT, few-shot, structured prompts | 20% |
| **Iteration Efficiency** | Turns to task completion | 20% |
| **Knowledge Gap Rate** | Missing context/specs detection | 10% |

#### Scoring Formula

```python
def prompt_engineering_score(conversation_history):
    """
    Calculate prompt engineering proficiency (0-100).

    Based on research findings:
    - 54.7% gap rate = poor proficiency
    - 13.2% gap rate = high proficiency
    - Numbered steps = 87% better compliance
    """

    # Analyze all user messages
    user_messages = extract_user_messages(conversation_history)

    # Calculate component scores
    clarity = calculate_clarity_score(user_messages)  # 0-1
    specificity = calculate_specificity_score(user_messages)  # 0-1
    technique = detect_technique_usage(user_messages)  # 0-1
    iteration = calculate_iteration_efficiency(conversation_history)  # 0-1
    gap_rate = detect_knowledge_gaps(user_messages)  # 0-1 (inverted)

    # Weighted combination
    raw_score = (
        0.25 * clarity +
        0.25 * specificity +
        0.20 * technique +
        0.20 * iteration +
        0.10 * (1 - gap_rate)  # Lower gap rate = higher score
    )

    return int(raw_score * 100)
```

#### Clarity Detection Heuristics

```python
CLARITY_POSITIVE_SIGNALS = [
    r'\d+\.',              # Numbered steps
    r'specifically',       # Explicit specificity
    r'exactly',            # Precision language
    r'must include',       # Requirements
    r'format:',            # Output formatting
    r'<\w+>',              # XML tags (Claude-optimized)
]

CLARITY_NEGATIVE_SIGNALS = [
    r'maybe',              # Uncertainty
    r'kind of',            # Vagueness
    r'something like',     # Ambiguity
    r'etc\.?',             # Incomplete lists
    r'whatever',           # Low effort
    r'^.{1,20}$',          # Very short prompts (< 20 chars)
]
```

### 2.3 Dimension 2: Context Engineering Proficiency

#### Measurable Signals

| Signal | Detection Method | Weight |
|--------|-----------------|--------|
| **Context Efficiency** | Relevant vs irrelevant content ratio | 30% |
| **Position Awareness** | Critical info at start/end (not middle) | 25% |
| **Compression Skill** | Effective summarization when near limits | 25% |
| **Retrieval Patterns** | Strategic file/code inclusion | 20% |

#### Integration with Existing Context Rot Research

From `CONTEXT_ROT_RESEARCH.md`, we know:
- At 32k tokens, 11/12 models dropped below 50% short-context performance
- "Lost in the middle" effect is measurable
- Shuffled haystacks paradoxically improve performance

**New Metric**: Track user awareness of these effects through their context management behaviors.

```python
def context_engineering_score(sessions):
    """
    Calculate context engineering proficiency.

    Key insight from research:
    - Users who place instructions at END perform 36% better
    - Context occupancy > 85% signals compression need
    """

    scores = []
    for session in sessions:
        # Check context efficiency
        efficiency = calculate_context_relevance_ratio(session)

        # Check position awareness (critical info placement)
        position = check_instruction_positioning(session)

        # Check compression behavior near limits
        compression = analyze_compression_behavior(session)

        # Check retrieval patterns
        retrieval = analyze_retrieval_patterns(session)

        session_score = (
            0.30 * efficiency +
            0.25 * position +
            0.25 * compression +
            0.20 * retrieval
        )
        scores.append(session_score)

    return int(np.mean(scores) * 100)
```

### 2.4 Dimension 3: Memory Engineering Proficiency

#### Measurable Signals

| Signal | Detection Method | Weight |
|--------|-----------------|--------|
| **Cross-Session Continuity** | Reference to prior context | 30% |
| **Project Isolation** | Proper memory separation | 25% |
| **Memory Commands** | Explicit save/recall usage | 25% |
| **Redundancy Avoidance** | Not re-explaining known context | 20% |

#### Memory Utilization Patterns

```python
MEMORY_PROFICIENCY_INDICATORS = {
    'high': [
        'as we discussed',
        'continuing from',
        'based on our previous',
        'you mentioned earlier',
        'referring to the project',
    ],
    'low': [
        'let me re-explain',
        'to remind you',
        'as I said before',  # Re-stating unnecessarily
        'you probably don\'t remember',
    ]
}

def memory_engineering_score(user_sessions):
    """
    Assess memory engineering sophistication.

    Key insight: Users with strong memory skills show:
    - 40% fewer re-explanations
    - 60% better cross-session coherence
    - Strategic project isolation
    """

    continuity = measure_cross_session_continuity(user_sessions)
    isolation = check_project_isolation(user_sessions)
    commands = detect_memory_command_usage(user_sessions)
    redundancy = calculate_redundancy_rate(user_sessions)

    return int((
        0.30 * continuity +
        0.25 * isolation +
        0.25 * commands +
        0.20 * (1 - redundancy)
    ) * 100)
```

### 2.5 Dimension 4: Tool Use Proficiency

#### Measurable Signals

| Signal | Detection Method | Weight |
|--------|-----------------|--------|
| **Tool Discovery** | Appropriate tool requests | 25% |
| **Tool Composition** | Multi-tool workflows | 25% |
| **Parallel Execution** | Independent operations parallelized | 25% |
| **Error Recovery** | Graceful handling of tool failures | 25% |

#### Tool Use Maturity Levels

```python
TOOL_MATURITY_LEVELS = {
    'novice': {
        'patterns': [
            'one tool at a time',
            'sequential when parallel possible',
            'no error handling',
        ],
        'score_range': (0, 25),
    },
    'intermediate': {
        'patterns': [
            'appropriate tool selection',
            'some parallel execution',
            'basic retry on failure',
        ],
        'score_range': (25, 50),
    },
    'advanced': {
        'patterns': [
            'optimal tool selection',
            'parallelism when beneficial',
            'graceful degradation',
        ],
        'score_range': (50, 75),
    },
    'expert': {
        'patterns': [
            'tool composition chains',
            'context-aware tool selection',
            'proactive error prevention',
        ],
        'score_range': (75, 100),
    },
}
```

---

## Part 3: Commit History Analysis

### 3.1 AI-Assisted Coding Signals

Building on `GIT_METRICS_RESEARCH.md`, add AI-specific metrics:

| Signal | Detection Method | Insight |
|--------|-----------------|---------|
| **Code Clone Rate** | Pattern detection in commits | Over-reliance on AI suggestions |
| **Immediate Reversion Rate** | Commits followed by reverts | Quality of AI code review |
| **Commit Message Quality** | NLP analysis | Prompt clarity proxy |
| **Churn After AI Sessions** | Correlation with Claude usage | AI code stability |
| **Time-to-Commit** | Duration between Claude session and commit | Deliberation vs acceptance |

### 3.2 Correlation with Claude Sessions

```python
def correlate_git_claude_sessions(git_commits, claude_sessions):
    """
    Correlate git commits with Claude sessions to assess
    AI-assisted coding proficiency.

    Key metrics:
    - Code survival rate: AI-suggested code that persists
    - Modification rate: Changes to AI-generated code before commit
    - Quality indicators: Test additions, documentation
    """

    correlations = []

    for session in claude_sessions:
        # Find commits within 2 hours of session end
        nearby_commits = find_commits_in_window(
            git_commits,
            session.end_time,
            window_hours=2
        )

        for commit in nearby_commits:
            correlation = {
                'session_id': session.id,
                'commit_hash': commit.hash,
                'time_delta': commit.time - session.end_time,
                'lines_added': commit.additions,
                'lines_removed': commit.deletions,
                'files_changed': commit.files,
                'has_tests': detect_test_files(commit.files),
                'has_docs': detect_doc_changes(commit.files),
            }
            correlations.append(correlation)

    return analyze_correlations(correlations)
```

### 3.3 Code Quality Indicators

```python
AI_CODING_QUALITY_SIGNALS = {
    'positive': [
        'test file additions alongside code',
        'documentation updates',
        'type annotation additions',
        'error handling additions',
        'commit message references task/issue',
    ],
    'negative': [
        'immediate reverts (< 10 min)',
        'TODO/FIXME additions',
        'commented-out code',
        'duplicate code patterns',
        'security-sensitive patterns unchanged',
    ],
}

def ai_coding_proficiency_score(git_data, claude_data):
    """
    Calculate AI-assisted coding proficiency.

    Based on GitClear 2025 research:
    - 4x code clone growth = concerning
    - 88% retention rate = healthy
    - Test coverage correlation = quality indicator
    """

    # Code survival rate (AI code that persists)
    survival = calculate_code_survival_rate(git_data)

    # Quality practices
    quality = assess_quality_practices(git_data)

    # Clone detection
    clone_rate = detect_code_clones(git_data)

    # Correlation with session patterns
    session_correlation = correlate_sessions(git_data, claude_data)

    return int((
        0.35 * survival +
        0.30 * quality +
        0.20 * (1 - clone_rate) +  # Lower clone rate = better
        0.15 * session_correlation
    ) * 100)
```

---

## Part 4: Implementation Architecture

### 4.1 System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PROFICIENCY ASSESSMENT SYSTEM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  DATA SOURCES                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   ~/.claude  â”‚  â”‚  Git Repos   â”‚  â”‚   Settings   â”‚          â”‚
â”‚  â”‚   /projects  â”‚  â”‚  (detected)  â”‚  â”‚    /prefs    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                 â”‚                  â”‚                   â”‚
â”‚         â–¼                 â–¼                  â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              SIGNAL EXTRACTION LAYER                     â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚    â”‚
â”‚  â”‚  â”‚ Prompt     â”‚  â”‚ Context    â”‚  â”‚ Commit     â”‚        â”‚    â”‚
â”‚  â”‚  â”‚ Analysis   â”‚  â”‚ Analysis   â”‚  â”‚ Analysis   â”‚        â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚    â”‚
â”‚  â”‚  â”‚ Memory     â”‚  â”‚ Tool Use   â”‚  â”‚ Temporal   â”‚        â”‚    â”‚
â”‚  â”‚  â”‚ Patterns   â”‚  â”‚ Patterns   â”‚  â”‚ Patterns   â”‚        â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              PROFICIENCY SCORING ENGINE                  â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚  Dimension Scores (0-100 each)                  â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Prompt Engineering: 72                       â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Context Engineering: 65                      â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Memory Engineering: 58                       â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ Tool Use: 81                                 â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚  Composite Score: 69 (Percentile: 74th)         â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              INSIGHT GENERATION                          â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  â€¢ Strengths: "Expert tool composer"                    â”‚    â”‚
â”‚  â”‚  â€¢ Weaknesses: "Context often exceeds optimal length"   â”‚    â”‚
â”‚  â”‚  â€¢ Recommendations: "Try XML formatting for +15%"       â”‚    â”‚
â”‚  â”‚  â€¢ Trends: "Memory engineering improved 23% this month" â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Data Schema Extensions

```python
@dataclass
class ProficiencyAssessment:
    """
    Extension to ClaudeWrappedData for proficiency scoring.
    """

    # Dimension scores (0-100)
    prompt_engineering_score: int = 0
    context_engineering_score: int = 0
    memory_engineering_score: int = 0
    tool_use_score: int = 0

    # Composite metrics
    overall_proficiency: int = 0
    proficiency_percentile: int = 0  # Compared to other users

    # Trend data
    proficiency_trend: str = "stable"  # improving, stable, declining
    month_over_month_change: float = 0.0

    # Detailed breakdowns
    prompt_clarity_score: int = 0
    prompt_specificity_score: int = 0
    prompt_technique_score: int = 0
    prompt_iteration_efficiency: int = 0
    prompt_gap_rate: float = 0.0

    context_efficiency_score: int = 0
    context_position_awareness: int = 0
    context_compression_skill: int = 0

    memory_continuity_score: int = 0
    memory_isolation_score: int = 0

    tool_discovery_score: int = 0
    tool_composition_score: int = 0
    tool_parallelism_score: int = 0

    # AI-coding metrics
    ai_code_survival_rate: float = 0.0
    ai_code_clone_rate: float = 0.0
    ai_code_quality_score: int = 0

    # Actionable insights
    top_strength: str = ""
    primary_weakness: str = ""
    recommendations: List[str] = field(default_factory=list)

    # Skill progression
    skills_improved: List[str] = field(default_factory=list)
    skills_declined: List[str] = field(default_factory=list)
```

### 4.3 Insight Generation Templates

```python
INSIGHT_TEMPLATES = {
    'prompt_engineering': {
        'high': [
            "Your prompts are in the top {percentile}% for clarity and specificity.",
            "You use structured prompts {percentage}% of the time - well above average.",
            "Knowledge gap rate of {gap_rate}% puts you among expert prompters.",
        ],
        'medium': [
            "Your prompts show good fundamentals with room for improvement.",
            "Consider using numbered steps - research shows 87% better compliance.",
            "Your iteration count of {iterations} could be reduced with more specific initial prompts.",
        ],
        'low': [
            "Your prompts have a {gap_rate}% knowledge gap rate - aim for under 20%.",
            "Try adding specific output formats to your requests.",
            "XML formatting can improve your results by 15-20% with Claude.",
        ],
    },
    'context_engineering': {
        'high': [
            "Excellent context management - you're in the top {percentile}%.",
            "Your instruction positioning shows awareness of the 'lost in middle' effect.",
        ],
        'medium': [
            "You're using {occupancy}% of context on average - consider compression above 85%.",
            "Try placing critical instructions at the END of your prompts.",
        ],
        'low': [
            "Context efficiency is at {efficiency}% - aim for 70%+ relevant content.",
            "Your sessions hit context limits {limit_hits} times - consider summarization.",
        ],
    },
    'memory_engineering': {
        'high': [
            "Strong cross-session continuity - you rarely re-explain context.",
            "Effective project isolation keeps your workflows clean.",
        ],
        'medium': [
            "You re-explain context {redundancy_rate}% of the time - memory can help.",
            "Consider using explicit save/recall for persistent information.",
        ],
        'low': [
            "Low cross-session continuity detected - leverage Claude's memory features.",
            "Redundant explanations waste {wasted_tokens} tokens on average.",
        ],
    },
    'tool_use': {
        'high': [
            "Expert tool composer - you chain tools effectively {composition_rate}% of sessions.",
            "Parallel execution when appropriate shows advanced understanding.",
        ],
        'medium': [
            "Good tool discovery, but composition could improve.",
            "You could parallelize {parallel_opportunity}% more operations.",
        ],
        'low': [
            "Tool usage is primarily sequential - consider parallel operations.",
            "Error recovery patterns suggest more defensive prompting would help.",
        ],
    },
}
```

---

## Part 5: Existing Tools and Solutions

### 5.1 Tools to Leverage

| Tool | Purpose | Integration Approach |
|------|---------|---------------------|
| **Hercules** | Git history DAG analysis | Import for commit pattern analysis |
| **git2net** | Co-editing network extraction | Use for collaboration metrics |
| **GitClear** | ML-based code quality | API integration for clone detection |
| **EvalLM** | Interactive prompt evaluation | Methodology adaptation |
| **Swarmia** | AI coding tool impact | Benchmark comparison data |

### 5.2 Relevant Research Implementations

| Paper/Project | Implementation | Adaptation |
|--------------|----------------|------------|
| RPP Framework | Instance-wise prompt personalization | User preference learning |
| MemGPT | Structured memory blocks | Memory proficiency detection |
| SHADE-Arena | Alignment evaluation | Interaction pattern classification |
| MT-Bench | Multi-turn evaluation | Conversation quality metrics |

---

## Part 6: Actionable Recommendations

### 6.1 For Claude Wrapped Integration

#### Phase 1: Basic Proficiency Scoring
1. Implement prompt clarity/specificity detection
2. Add knowledge gap rate calculation
3. Calculate iteration efficiency metrics
4. Display 4-dimension radar chart

#### Phase 2: Trend Analysis
1. Track proficiency over time
2. Identify improving/declining skills
3. Generate personalized recommendations
4. Add month-over-month comparisons

#### Phase 3: Git Correlation
1. Integrate commit pattern analysis
2. Correlate AI sessions with commits
3. Calculate code survival rates
4. Detect code clone patterns

#### Phase 4: Cross-Model Insights
1. Track model-specific proficiency
2. Identify optimal model-task pairings
3. Generate model switching recommendations

### 6.2 Display Recommendations

#### New Wrapped Sections

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOUR PROMPTING PROFICIENCY                            â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    Overall                        â”‚ â”‚
â”‚  â”‚                      69                           â”‚ â”‚
â”‚  â”‚              Top 26% of users                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Prompt    â”‚  Context   â”‚  Memory    â”‚  Tools   â”‚ â”‚
â”‚  â”‚    72      â”‚    65      â”‚    58      â”‚    81    â”‚ â”‚
â”‚  â”‚    â†‘5%     â”‚    â†“2%     â”‚    â†‘12%    â”‚    â†’     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚
â”‚  TOP STRENGTH: Expert Tool Composer                   â”‚
â”‚  You chain tools effectively in 78% of sessions       â”‚
â”‚                                                        â”‚
â”‚  BIGGEST OPPORTUNITY: Memory Engineering              â”‚
â”‚  You re-explain context 34% of the time              â”‚
â”‚  â†’ Try: "As we discussed in project X..."            â”‚
â”‚                                                        â”‚
â”‚  THIS YEAR YOU IMPROVED:                              â”‚
â”‚  â€¢ Memory continuity +23%                             â”‚
â”‚  â€¢ Prompt specificity +15%                           â”‚
â”‚  â€¢ Context efficiency +8%                            â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### AI Coding Quality Section

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOUR AI-ASSISTED CODING                               â”‚
â”‚                                                        â”‚
â”‚  Code Survival Rate: 87%                              â”‚
â”‚  (AI-suggested code that made it to production)       â”‚
â”‚                                                        â”‚
â”‚  Code Clone Rate: 12%                                 â”‚
â”‚  (Below concerning threshold of 25%)                  â”‚
â”‚                                                        â”‚
â”‚  Quality Signals:                                      â”‚
â”‚  âœ“ Tests added with AI code: 67% of commits          â”‚
â”‚  âœ“ Documentation updates: 45% of commits             â”‚
â”‚  âœ“ Average review time: 12 min (thoughtful!)         â”‚
â”‚                                                        â”‚
â”‚  INSIGHT: You're a Thoughtful Adopter                 â”‚
â”‚  You review AI suggestions before committing          â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Part 6.5: Signature Prompts & Repeated Patterns

### 6.5.1 Concept: "Your Prompt DNA"

A fun, engaging feature that surfaces the user's most common prompt patterns, phrases, and "catchphrases" - similar to how Spotify Wrapped shows top songs.

**User Value**:
- Self-awareness of prompting habits
- Identify patterns that work (or don't)
- Shareable/entertaining content
- Basis for personalized system prompts

### 6.5.2 What to Extract

#### A. Opening Phrases (Prompt Starters)

```python
OPENING_PATTERN_CATEGORIES = {
    'polite': [
        'please', 'could you', 'would you mind', 'can you help',
    ],
    'direct': [
        'write', 'create', 'make', 'build', 'generate', 'fix',
    ],
    'exploratory': [
        'how do i', 'what is', 'explain', 'why does', 'help me understand',
    ],
    'contextual': [
        'given', 'considering', 'based on', 'in the context of',
    ],
    'imperative': [
        'do not', 'always', 'never', 'make sure', 'ensure',
    ],
}

def extract_opening_patterns(messages):
    """
    Extract how users typically start their prompts.

    Returns: {pattern_type: count, top_phrases: [...]}
    """
    openings = []
    for msg in messages:
        # Get first 10 words
        opening = ' '.join(msg.split()[:10]).lower()
        openings.append(opening)

    return cluster_similar_openings(openings)
```

#### B. Repeated Instructions (Your "House Rules")

```python
def extract_repeated_instructions(messages, min_occurrences=3):
    """
    Find instructions that appear repeatedly across sessions.

    These are the user's implicit "system prompt" preferences.

    Examples:
    - "use typescript"
    - "keep it concise"
    - "no emojis"
    - "explain your reasoning"
    - "write tests first"
    """

    # Extract instruction-like phrases
    instruction_patterns = [
        r'always\s+\w+',
        r'never\s+\w+',
        r'use\s+\w+',
        r'don\'t\s+\w+',
        r'make sure\s+.+',
        r'keep\s+it\s+\w+',
        r'be\s+\w+',  # "be concise", "be specific"
    ]

    instructions = defaultdict(int)
    for msg in messages:
        for pattern in instruction_patterns:
            matches = re.findall(pattern, msg.lower())
            for match in matches:
                instructions[match] += 1

    return {k: v for k, v in instructions.items() if v >= min_occurrences}
```

#### C. Signature Phrases (Your Catchphrases)

```python
def extract_signature_phrases(messages, n_gram_range=(3, 6)):
    """
    Find unique multi-word phrases the user uses repeatedly.

    These become the user's "prompt fingerprint".

    Examples:
    - "let's think step by step"
    - "in a single file"
    - "without any external dependencies"
    - "optimized for readability"
    """

    all_ngrams = []
    for msg in messages:
        tokens = tokenize(msg)
        for n in range(n_gram_range[0], n_gram_range[1] + 1):
            ngrams = extract_ngrams(tokens, n)
            all_ngrams.extend(ngrams)

    # Count and filter
    ngram_counts = Counter(all_ngrams)

    # Filter: must appear 3+ times, not generic
    signature = {
        phrase: count
        for phrase, count in ngram_counts.items()
        if count >= 3 and not is_generic_phrase(phrase)
    }

    return sorted(signature.items(), key=lambda x: -x[1])[:10]
```

#### D. Context Patterns (What You Always Mention)

```python
def extract_context_patterns(messages):
    """
    Find what context users consistently provide.

    Examples:
    - Tech stack mentions: "using React", "in Python 3.11"
    - Environment: "on macOS", "in production"
    - Constraints: "under 100 lines", "no dependencies"
    - Quality: "production-ready", "well-documented"
    """

    context_categories = {
        'tech_stack': extract_tech_mentions(messages),
        'environment': extract_env_mentions(messages),
        'constraints': extract_constraint_mentions(messages),
        'quality_requirements': extract_quality_mentions(messages),
    }

    return context_categories
```

#### E. Tool Request Patterns

```python
def extract_tool_patterns(messages):
    """
    How does the user typically request tool usage?

    Examples:
    - "read the file first"
    - "search for"
    - "run the tests"
    - "check if"
    """

    tool_verbs = [
        'read', 'write', 'edit', 'search', 'find', 'grep',
        'run', 'execute', 'test', 'build', 'deploy',
        'check', 'verify', 'validate', 'lint',
        'commit', 'push', 'pull', 'merge',
    ]

    patterns = defaultdict(int)
    for msg in messages:
        for verb in tool_verbs:
            if re.search(rf'\b{verb}\b', msg.lower()):
                # Extract the full phrase
                match = re.search(rf'{verb}\s+[\w\s]{{1,20}}', msg.lower())
                if match:
                    patterns[match.group()] += 1

    return patterns
```

### 6.5.3 Analysis & Insights

```python
@dataclass
class SignaturePromptsAnalysis:
    """Data structure for signature prompts feature."""

    # Top repeated elements
    top_opening_phrase: str = ""           # "How do I..."
    top_opening_count: int = 0
    opening_style: str = ""                # "exploratory", "direct", etc.

    # House rules (repeated instructions)
    house_rules: List[str] = field(default_factory=list)
    # e.g., ["use typescript", "keep it concise", "no comments"]

    # Signature catchphrases
    catchphrases: List[Tuple[str, int]] = field(default_factory=list)
    # e.g., [("let's think step by step", 47), ("in a single file", 23)]

    # Most mentioned tech
    top_tech_mentions: List[str] = field(default_factory=list)
    # e.g., ["Python", "React", "PostgreSQL"]

    # Quality preferences
    quality_keywords: List[str] = field(default_factory=list)
    # e.g., ["concise", "production-ready", "well-tested"]

    # Unique vocabulary
    unique_words: List[str] = field(default_factory=list)
    # Words user uses more than average

    # Prompt length preferences
    avg_prompt_length: int = 0
    prompt_length_style: str = ""  # "terse", "detailed", "verbose"

    # Question vs statement ratio
    question_ratio: float = 0.0
    communication_style: str = ""  # "inquisitive", "directive"
```

### 6.5.4 Display: Signature Prompts Section

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOUR PROMPT DNA                                       â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  "How do I..."                                    â”‚ â”‚
â”‚  â”‚  Your signature opening (used 234 times)          â”‚ â”‚
â”‚  â”‚                                                    â”‚ â”‚
â”‚  â”‚  Style: THE EXPLORER                              â”‚ â”‚
â”‚  â”‚  You ask questions 73% of the time                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚
â”‚  YOUR CATCHPHRASES                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  #1  "let's think step by step"      47 times    â”‚ â”‚
â”‚  â”‚  #2  "without any dependencies"      34 times    â”‚ â”‚
â”‚  â”‚  #3  "in a single file"              28 times    â”‚ â”‚
â”‚  â”‚  #4  "keep it simple"                25 times    â”‚ â”‚
â”‚  â”‚  #5  "production ready"              19 times    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚
â”‚  YOUR HOUSE RULES                                     â”‚
â”‚  (Instructions you give Claude repeatedly)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ğŸ   "use TypeScript"                 89 times   â”‚ â”‚
â”‚  â”‚  ğŸ   "no emojis"                      67 times   â”‚ â”‚
â”‚  â”‚  ğŸ   "be concise"                     52 times   â”‚ â”‚
â”‚  â”‚  ğŸ   "explain your reasoning"         41 times   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚
â”‚  ğŸ’¡ TIP: Add these to your CLAUDE.md file to save    â”‚
â”‚     tokens and get consistent behavior!               â”‚
â”‚                                                        â”‚
â”‚  YOUR TECH STACK (most mentioned)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Python â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  67%            â”‚ â”‚
â”‚  â”‚  React  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  28%            â”‚ â”‚
â”‚  â”‚  SQL    â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   5%            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                        â”‚
â”‚  PROMPT LENGTH STYLE: The Novelist ğŸ“š                 â”‚
â”‚  Avg prompt: 127 words (top 15% verbosity)           â”‚
â”‚  You provide rich context - Claude appreciates it!    â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.5.5 Fun Personality Mappings

```python
PROMPT_PERSONALITIES = {
    'the_explorer': {
        'triggers': {'question_ratio': (0.6, 1.0)},
        'description': "You learn by asking. Your curiosity drives innovation.",
        'icon': 'ğŸ”',
    },
    'the_commander': {
        'triggers': {'opening_style': 'direct', 'question_ratio': (0, 0.3)},
        'description': "Direct and decisive. You know what you want.",
        'icon': 'âš”ï¸',
    },
    'the_architect': {
        'triggers': {'catchphrases_contain': ['step by step', 'first', 'then']},
        'description': "You think in systems. Everything has a structure.",
        'icon': 'ğŸ—ï¸',
    },
    'the_minimalist': {
        'triggers': {'avg_prompt_length': (0, 50), 'house_rules_contain': 'concise'},
        'description': "Less is more. Every word earns its place.",
        'icon': 'âœ¨',
    },
    'the_novelist': {
        'triggers': {'avg_prompt_length': (100, 999)},
        'description': "Context is king. You leave nothing to chance.",
        'icon': 'ğŸ“š',
    },
    'the_perfectionist': {
        'triggers': {'quality_keywords_count': (5, 99)},
        'description': "Production-ready or bust. Quality is non-negotiable.",
        'icon': 'ğŸ’',
    },
}
```

### 6.5.6 Actionable Output: Auto-Generated CLAUDE.md

```python
def generate_claude_md_suggestions(signature_analysis):
    """
    Generate a suggested CLAUDE.md file based on user's patterns.

    This saves tokens by pre-loading their "house rules".
    """

    md_content = f"""# Auto-Generated Preferences
Based on your {signature_analysis.total_messages} messages this year.

## Your Communication Style
- You prefer {signature_analysis.communication_style} interactions
- Average prompt length: {signature_analysis.avg_prompt_length} words

## Your House Rules
These instructions appeared repeatedly in your prompts:
"""

    for rule in signature_analysis.house_rules[:5]:
        md_content += f"- {rule}\n"

    md_content += f"""
## Your Tech Stack
Primary technologies you work with:
"""

    for tech in signature_analysis.top_tech_mentions[:5]:
        md_content += f"- {tech}\n"

    md_content += f"""
## Quality Preferences
{', '.join(signature_analysis.quality_keywords[:5])}

---
*Generated from your Claude Wrapped 2025 analysis*
"""

    return md_content
```

### 6.5.7 Implementation Notes

**Privacy Considerations**:
- All analysis happens locally
- No prompt content leaves the device
- Only aggregate patterns shown
- User can exclude sensitive projects

**Performance**:
- N-gram extraction can be expensive
- Consider sampling for users with 100k+ messages
- Cache results after first computation

**Edge Cases**:
- New users (< 50 messages): Show "Not enough data yet"
- Single-project users: May have skewed patterns
- Multi-language users: Detect and separate by language

---

## Part 7: Research Limitations and Future Work

### 7.1 Current Limitations

1. **No ground truth**: User proficiency cannot be directly measured
2. **Privacy considerations**: Deep conversation analysis may be sensitive
3. **Model specificity**: Techniques optimal for Claude may not transfer
4. **Temporal effects**: Proficiency may vary by task type, time of day

### 7.2 Future Research Directions

1. **Longitudinal studies**: Track proficiency changes over months
2. **A/B testing**: Validate that insights improve outcomes
3. **Cross-model transfer**: Test proficiency portability
4. **Causal analysis**: Determine if high proficiency causes better outcomes

### 7.3 Validation Approach

```python
VALIDATION_METRICS = {
    'task_completion_rate': {
        'hypothesis': 'Higher proficiency â†’ more tasks completed',
        'measurement': 'Successful task completions / total attempts',
    },
    'iteration_reduction': {
        'hypothesis': 'Recommendations reduce iteration count',
        'measurement': 'Pre/post recommendation iteration counts',
    },
    'user_satisfaction': {
        'hypothesis': 'Proficient users report higher satisfaction',
        'measurement': 'Survey correlation with proficiency scores',
    },
    'code_quality': {
        'hypothesis': 'Higher proficiency â†’ better code outcomes',
        'measurement': 'Defect rate correlation with proficiency',
    },
}
```

---

## Appendix A: Full Source List

### Academic Papers
- [A Systematic Survey of Prompt Engineering](https://arxiv.org/abs/2402.07927) - Sahoo et al., 2024
- [Exploring Prompt Engineering in Enterprise](https://arxiv.org/abs/2403.08950) - 2024
- [From Prompting to Partnering](https://arxiv.org/abs/2503.00681) - March 2025
- [Context Engineering Survey](https://arxiv.org/html/2507.13334v1) - 2025
- [Multi-Turn Conversation Evaluation](https://arxiv.org/html/2503.22458v1) - 2025
- [Prompt Knowledge Gaps Research](https://arxiv.org/html/2501.11709v1) - 2025
- [EvalLM: Interactive Evaluation](https://dl.acm.org/doi/10.1145/3613904.3642216) - CHI 2024
- [Reinforced Prompt Personalization](https://dl.acm.org/doi/10.1145/3716320) - ACM 2025
- [git2net: Co-editing Networks](https://link.springer.com/article/10.1007/s10664-020-09928-2) - ESE 2020

### Industry Research
- [Anthropic Prompt Engineering](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview)
- [Anthropic Memory Feature](https://www.anthropic.com/news/memory)
- [Anthropic Context Management](https://anthropic.com/news/context-management)
- [JetBrains Context Management (NeurIPS 2025)](https://blog.jetbrains.com/research/2025/12/efficient-context-management/)
- [Langchain Context Engineering](https://blog.langchain.com/context-engineering-for-agents/)
- [Letta Memory Blocks](https://www.letta.com/blog/memory-blocks)
- [GitClear Code Analysis](https://www.gitclear.com/code_analysis_beyond_lines_of_code)
- [Swarmia AI Impact](https://www.swarmia.com/product/ai-impact/)

### Tools and Frameworks
- [Hercules Git Analyzer](https://github.com/src-d/hercules)
- [CARE Framework](https://www.linkedin.com/pulse/introducing-care-new-way-measure-effectiveness-prompts-reuven-cohen-ls9bf)
- [KDnuggets Prompt Metrics](https://www.kdnuggets.com/measuring-prompt-effectiveness-metrics-and-methods)
- [Agentic Design Patterns](https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/)

---

## Appendix B: Metric Reference Card

### Quick Reference: What to Measure

| Category | Metric | Good | Average | Poor |
|----------|--------|------|---------|------|
| **Prompt** | Knowledge Gap Rate | <15% | 15-40% | >40% |
| **Prompt** | Iteration Count | <3 | 3-6 | >6 |
| **Prompt** | Clarity Score | >80 | 50-80 | <50 |
| **Context** | Efficiency Ratio | >70% | 50-70% | <50% |
| **Context** | Position Awareness | Yes | Partial | No |
| **Memory** | Redundancy Rate | <10% | 10-30% | >30% |
| **Memory** | Cross-Session Refs | >50% | 20-50% | <20% |
| **Tools** | Parallel Utilization | >60% | 30-60% | <30% |
| **Tools** | Composition Rate | >40% | 20-40% | <20% |
| **AI Code** | Survival Rate | >85% | 70-85% | <70% |
| **AI Code** | Clone Rate | <15% | 15-25% | >25% |

---

*Research compiled December 2025 for Claude Wrapped enhancement*
